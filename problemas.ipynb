{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d872f76",
   "metadata": {},
   "source": [
    "### Carlos Alberto Mentado Reyes A01276065\n",
    "### Fernanda Díaz Gutiérrez A01639572"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c08a2b",
   "metadata": {},
   "source": [
    "Para importar el dataset corran en terminal\n",
    "_pip install uimclrepo_\n",
    "\n",
    "\n",
    "En el gitignore pongan los archivos de sus virtual environments uwu pofavo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff17f206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install ucimlrepo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk \n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a16e5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "parkinsons_telemonitoring = fetch_ucirepo(id=189) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = parkinsons_telemonitoring.data.features \n",
    "y = parkinsons_telemonitoring.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(parkinsons_telemonitoring.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(parkinsons_telemonitoring.variables) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162fe5b8",
   "metadata": {},
   "source": [
    "# Modelo lineal\n",
    "## Entrenar el modelo con las variables asignadas en el ejercicio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d08a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usamos un modelo de regresión lineal\n",
    "#SGDRegressor es un modelo de regresión lineal que se basa en el descenso de gradiente, usado en el notebook anterior\n",
    "model = make_pipeline(StandardScaler(), SGDRegressor(max_iter=1000, tol=1e-3))\n",
    "target = y[\"total_UPDRS\"]\n",
    "\n",
    "#Usamos np.array(feature).reshape(-1, 1) porque usando solo una variable necesitamos que tenga la forma correcta\n",
    "y_pred = cross_val_predict(model, X, target, cv=5)\n",
    "\n",
    "#Para evaluar el resultado de la predicción con cv checamos el R2 y el MSE\n",
    "print(\"R²:\", r2_score(target, y_pred))\n",
    "print(\"MSE:\", mean_squared_error(target, y_pred))\n",
    "\n",
    "scores = cross_val_score(model, X, target, cv=5)\n",
    "print(\"Cross-validated scores:\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9e55eb",
   "metadata": {},
   "source": [
    "# 4. Modelo No Lineal (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad827b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# cv 5 folds \n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# pipeline escalado + KNN\n",
    "knn_pipe = make_pipeline(StandardScaler(), KNeighborsRegressor())\n",
    "\n",
    "# reporte (media y std por métrica)\n",
    "def cv_report(model, X, y, cv):\n",
    "    out = {}\n",
    "    scorings = {\n",
    "        \"R2\": \"r2\",\n",
    "        \"RMSE\": \"neg_root_mean_squared_error\",\n",
    "        \"MAE\": \"neg_mean_absolute_error\",\n",
    "        \"MSE\": \"neg_mean_squared_error\"  \n",
    "    }\n",
    "    for name, scoring in scorings.items():\n",
    "        scores = cross_val_score(model, X, y, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "        if name in (\"RMSE\", \"MAE\", \"MSE\"):\n",
    "            scores = -scores  # pasar a positivo\n",
    "        out[name] = (scores.mean(), scores.std())\n",
    "    return out\n",
    "\n",
    "# cv knn\n",
    "from sklearn.model_selection import validation_curve\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if isinstance(y, pd.DataFrame):\n",
    "    if \"total_UPDRS\" in y.columns:\n",
    "        y = y[\"total_UPDRS\"].to_numpy().ravel()\n",
    "    else:\n",
    "        y = y.iloc[:, 0].to_numpy().ravel()\n",
    "elif isinstance(y, pd.Series):\n",
    "    y = y.to_numpy().ravel()\n",
    "else:\n",
    "    y = np.asarray(y).ravel()\n",
    "# print(\"y shape ->\", y.shape)\n",
    "\n",
    "metricas = {\n",
    "    \"R2\": \"r2\",\n",
    "    \"MAE\": \"neg_mean_absolute_error\",\n",
    "    \"RMSE\": \"neg_root_mean_squared_error\"\n",
    "}\n",
    "k_vals = np.arange(1, 21)\n",
    "\n",
    "curvas_val = {}\n",
    "for metrica, scoring in metricas.items():\n",
    "    train_scores, valid_scores = validation_curve(\n",
    "        knn_pipe, X, y,\n",
    "        param_name=\"kneighborsregressor__n_neighbors\",\n",
    "        param_range=k_vals,\n",
    "        cv=cv,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    if metrica in (\"MAE\",\"RMSE\"):\n",
    "        train_scores, valid_scores = -train_scores, -valid_scores  # signo positivo en MAE/RMSE\n",
    "    curvas_val[metrica] = {\n",
    "        \"train_mean\": train_scores.mean(axis=1), \"train_std\": train_scores.std(axis=1, ddof=1),\n",
    "        \"valid_mean\": valid_scores.mean(axis=1), \"valid_std\": valid_scores.std(axis=1, ddof=1)\n",
    "    }\n",
    "\n",
    "# k óptimo por MAE (min), por R2 (máx) y RMSE (min)\n",
    "bestk_mae  = int(k_vals[np.argmin(curvas_val[\"MAE\"][\"valid_mean\"])])\n",
    "bestk_rmse = int(k_vals[np.argmin(curvas_val[\"RMSE\"][\"valid_mean\"])])\n",
    "bestk_r2   = int(k_vals[np.argmax(curvas_val[\"R2\"][\"valid_mean\"])])\n",
    "\n",
    "print(f\"mejor k por MAE : {bestk_mae}\")\n",
    "print(f\"mejor k por RMSE: {bestk_rmse}\")\n",
    "print(f\"mejor k por R2  : {bestk_r2}\")\n",
    "\n",
    "# resumen (curva validación media ± std) para c/k\n",
    "sum_val = pd.DataFrame({\n",
    "    \"k\": k_vals,\n",
    "    \"R2_mean\":  curvas_val[\"R2\"][\"valid_mean\"],\n",
    "    \"R2_std\":   curvas_val[\"R2\"][\"valid_std\"],\n",
    "    \"MAE_mean\": curvas_val[\"MAE\"][\"valid_mean\"],\n",
    "    \"MAE_std\":  curvas_val[\"MAE\"][\"valid_std\"],\n",
    "    \"RMSE_mean\":curvas_val[\"RMSE\"][\"valid_mean\"],\n",
    "    \"RMSE_std\": curvas_val[\"RMSE\"][\"valid_std\"],\n",
    "}).round(4)\n",
    "sum_val\n",
    "\n",
    "# gráficas (1 por métrica)\n",
    "for metrica in [\"MAE\",\"RMSE\",\"R2\"]:\n",
    "    m = curvas_val[metrica]\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.plot(k_vals, m[\"train_mean\"], marker=\"o\", label=\"entrenamiento\")\n",
    "    plt.fill_between(k_vals, m[\"train_mean\"]-m[\"train_std\"], m[\"train_mean\"]+m[\"train_std\"], alpha=0.2)\n",
    "    plt.plot(k_vals, m[\"valid_mean\"], marker=\"o\", label=\"validación cv\")\n",
    "    plt.fill_between(k_vals, m[\"valid_mean\"]-m[\"valid_std\"], m[\"valid_mean\"]+m[\"valid_std\"], alpha=0.2)\n",
    "    if metrica in (\"MAE\",\"RMSE\"):\n",
    "        best_k_tmp = int(k_vals[np.argmin(m[\"valid_mean\"])])\n",
    "        plt.axvline(best_k_tmp, ls=\"--\", label=f\"mejor k por {metrica} = {best_k_tmp}\")\n",
    "        ylabel = metrica + \" (menor = mejor)\"\n",
    "    else:\n",
    "        best_k_tmp = int(k_vals[np.argmax(m[\"valid_mean\"])])\n",
    "        plt.axvline(best_k_tmp, ls=\"--\", label=f\"mejor k por {metrica} = {best_k_tmp}\")\n",
    "        ylabel = metrica + \" (mayor = mejor)\"\n",
    "    plt.xlabel(\"núm.vecinos (k)\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(f\"curva validación knn ({metrica})\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# k óptimo el de RMSE\n",
    "best_k = bestk_rmse\n",
    "\n",
    "# comparación final contra el modelo lineal SGDRegressor \n",
    "from sklearn.linear_model import SGDRegressor  \n",
    "knn_final = make_pipeline(StandardScaler(), KNeighborsRegressor(n_neighbors=best_k))\n",
    "res_knn = cv_report(knn_final, X, y, cv)\n",
    "sgd_lineal = make_pipeline(StandardScaler(), SGDRegressor(max_iter=1000, tol=1e-3, random_state=42))\n",
    "res_sgd = cv_report(sgd_lineal, X, y, cv)\n",
    "res_cmp = pd.DataFrame(\n",
    "    {\n",
    "        \"lineal (SGD)\": [f\"{res_sgd['R2'][0]:.4f} ± {res_sgd['R2'][1]:.4f}\",\n",
    "                         f\"{res_sgd['RMSE'][0]:.4f} ± {res_sgd['RMSE'][1]:.4f}\",\n",
    "                         f\"{res_sgd['MAE'][0]:.4f} ± {res_sgd['MAE'][1]:.4f}\",\n",
    "                         f\"{res_sgd['MSE'][0]:.4f} ± {res_sgd['MSE'][1]:.4f}\"],\n",
    "        f\"KNN (k={best_k})\": [f\"{res_knn['R2'][0]:.4f} ± {res_knn['R2'][1]:.4f}\",\n",
    "                             f\"{res_knn['RMSE'][0]:.4f} ± {res_knn['RMSE'][1]:.4f}\",\n",
    "                             f\"{res_knn['MAE'][0]:.4f} ± {res_knn['MAE'][1]:.4f}\",\n",
    "                             f\"{res_knn['MSE'][0]:.4f} ± {res_knn['MSE'][1]:.4f}\"]\n",
    "    },\n",
    "    index=[\"R2\", \"RMSE\", \"MAE\", \"MSE\"]\n",
    ")\n",
    "print(\"comparación lineal (SGD) vs knn (media ± std, cv=5):\")\n",
    "display(res_cmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29ed98b",
   "metadata": {},
   "source": [
    "### 4. Observaciones / conclusiones KNN vs lineal:\n",
    "\n",
    "Cuando se entrena el modelo KNN con crossvalidation de 5 folds y se exploran los valores de k del 1-20, se obtuvo que el menor MAE sucede en k=1 pero hay mucho overfitting. Cuando se analiza RMSE y R2, el mejor balance sesgo/var se obtiene en k=6, en donde el modelo alcanza aprox. R2= 0.6, RMSE=6.3 y MAE=4.03. A comparación del lineal, que logró solamente R2=0.17, RMSE=9.7 y MAE=8.07, podemos entonces decir que el KNN supera al modelo lineal en las métricas porque captura mejor las relaciones (nolineales) en los datos para predecir la severidad de la enfermedad (total_UPDRS).\n",
    "\n",
    "Nota: los números del lineal aquí reportados son del mismo modelo (SGDRegressor) re-evaluado con el mismo protocolo de cv y métricas que KNN, por ello pueden diferir un poco de la pt.1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
